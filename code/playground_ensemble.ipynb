{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 448x640 1 person, 1 boat, 89.1ms\n",
      "Speed: 3.5ms preprocess, 89.1ms inference, 1.0ms postprocess per image at shape (1, 3, 448, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\chowd/.cache\\torch\\hub\\facebookresearch_detr_main\n"
     ]
    }
   ],
   "source": [
    "# from detectron2_wrapper import run_detectron\n",
    "from detr_wrapper import run_detr\n",
    "from yolo_wrapper import run_yolo\n",
    "\n",
    "# Run all the models on the same image\n",
    "test_image = '../data/Images/image5.jpg'\n",
    "\n",
    "yolo_output = run_yolo(test_image)\n",
    "detr_boxes, detr_scores, detr_labels = run_detr(test_image)\n",
    "# detectron_output = run_detectron(test_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Function for YOLO output\n",
    "def transform_yolo_output(yolo_output):\n",
    "    \"\"\"\n",
    "    Transforms YOLO output into standardized format.\n",
    "    \"\"\"\n",
    "    boxes = yolo_output.boxes.xyxy.cpu().numpy()  # Bounding boxes\n",
    "    scores = yolo_output.boxes.conf.cpu().numpy()  # Confidence scores\n",
    "    classes = yolo_output.boxes.cls.cpu().numpy()  # Class predictions\n",
    "\n",
    "    boxes = np.array(boxes)  # No conversion needed\n",
    "    scores = np.array(scores)\n",
    "    classes = np.array(classes, dtype=int)\n",
    "    return boxes, scores, classes\n",
    "\n",
    "# Function for DETR output\n",
    "def transform_detr_output(detr_boxes, detr_scores, detr_classes):\n",
    "    \"\"\"\n",
    "    Transforms DETR output into standardized format.\n",
    "    \"\"\"\n",
    "    boxes = detr_boxes.cpu().numpy() if isinstance(detr_boxes, torch.Tensor) else np.array(detr_boxes)\n",
    "    scores = detr_scores.cpu().numpy() if isinstance(detr_scores, torch.Tensor) else np.array(detr_scores)\n",
    "    classes = detr_classes.cpu().numpy().astype(int) if isinstance(detr_classes, torch.Tensor) else np.array(detr_classes, dtype=int)\n",
    "    return boxes, scores, classes\n",
    "\n",
    "# Function for Detectron2 output\n",
    "def transform_detectron_output(detectron_output):\n",
    "    \"\"\"\n",
    "    Transforms Detectron2 output Instances object into standardized format.\n",
    "    \"\"\"\n",
    "    boxes = detectron_output.pred_boxes.tensor.cpu().numpy()\n",
    "    scores = detectron_output.scores.cpu().numpy()\n",
    "    classes = detectron_output.pred_classes.cpu().numpy().astype(int)\n",
    "    return boxes, scores, classes\n",
    "\n",
    "\n",
    "boxes_yolo, scores_yolo, classes_yolo = transform_yolo_output(yolo_output)\n",
    "boxes_detr, scores_detr, classes_detr = transform_detr_output(detr_boxes, detr_scores, detr_labels)\n",
    "print(boxes_yolo, scores_yolo, classes_yolo)\n",
    "print(boxes_detr, scores_detr, classes_detr)\n",
    "\n",
    "# boxes_detectron, scores_detectron, classes_detectron = transform_detectron_output(detectron_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IoU Matrix:\n",
      "IoU[0][0] = 1.0000\tIoU[0][1] = 0.2038\tIoU[0][2] = 0.2647\tIoU[0][3] = 0.9157\t\n",
      "IoU[1][0] = 0.2038\tIoU[1][1] = 1.0000\tIoU[1][2] = 0.6579\tIoU[1][3] = 0.1920\t\n",
      "IoU[2][0] = 0.2647\tIoU[2][1] = 0.6579\tIoU[2][2] = 1.0000\tIoU[2][3] = 0.2500\t\n",
      "IoU[3][0] = 0.9157\tIoU[3][1] = 0.1920\tIoU[3][2] = 0.2500\tIoU[3][3] = 1.0000\t\n",
      "\n",
      "Box 0: Initial box [     166.19      130.83      621.33      343.04], Score: 0.8051950335502625, Class: 8\n",
      "Group indices (overlapping boxes with IoU > 0.5): [0, 3]\n",
      "IoUs with group indices: [1.0, 0.9156527519226074]\n",
      "\n",
      "Box 1: Initial box [     250.78      67.302       413.7       264.6], Score: 0.7584846615791321, Class: 0\n",
      "Group indices (overlapping boxes with IoU > 0.5): [1, 2]\n",
      "IoUs with group indices: [1.0, 0.6579228043556213]\n",
      "Aggregated boxes: [[     146.84      129.75      621.31      342.92]\n",
      " [     216.32      66.116      407.34      266.68]]\n",
      "Aggregated scores: [    0.85298     0.86742]\n",
      "Aggregated classes: [8 0]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torchvision.ops import box_iou\n",
    "\n",
    "def aggregate_boxes(model_outputs, iou_threshold=0.5):\n",
    "    \"\"\"\n",
    "    Aggregates bounding boxes, scores, and classes from multiple models based on overlap using Weighted Box Fusion.\n",
    "    \n",
    "    Arguments:\n",
    "        model_outputs (list): List of tuples, where each tuple contains (boxes, scores, classes) arrays.\n",
    "        iou_threshold (float): IoU threshold to consider boxes as overlapping.\n",
    "    \n",
    "    Returns:\n",
    "        Aggregated boxes, scores, and classes as numpy arrays.\n",
    "    \"\"\"\n",
    "    # Unpack the model outputs into lists of boxes, scores, and classes\n",
    "    boxes_list, scores_list, classes_list = zip(*model_outputs)\n",
    "\n",
    "    # Stack all boxes, concatenate all scores and classes\n",
    "    all_boxes = np.vstack(boxes_list)\n",
    "    all_scores = np.concatenate(scores_list)\n",
    "    all_classes = np.concatenate(classes_list)\n",
    "\n",
    "    # Convert all boxes to a torch tensor for box_iou compatibility\n",
    "    all_boxes_tensor = torch.tensor(all_boxes, dtype=torch.float32)\n",
    "\n",
    "    # Calculate IoU matrix for all pairs of boxes\n",
    "    iou_matrix = box_iou(all_boxes_tensor, all_boxes_tensor)\n",
    "\n",
    "    # Print the IoU matrix for debugging\n",
    "    print(\"IoU Matrix:\")\n",
    "    for i in range(iou_matrix.shape[0]):\n",
    "        for j in range(iou_matrix.shape[1]):\n",
    "            print(f\"IoU[{i}][{j}] = {iou_matrix[i, j]:.4f}\", end=\"\\t\")\n",
    "        print()  # Newline for readability\n",
    "\n",
    "    # Lists to store final aggregated results\n",
    "    final_boxes, final_scores, final_classes = [], [], []\n",
    "    used_indices = set()\n",
    "\n",
    "    # Loop through each box and aggregate based on IoU only\n",
    "    for i, (box, score, cls) in enumerate(zip(all_boxes, all_scores, all_classes)):\n",
    "        if i in used_indices:\n",
    "            continue\n",
    "\n",
    "        # Find all boxes that overlap with the current box, ignoring class\n",
    "        overlaps = (iou_matrix[i] > iou_threshold).nonzero(as_tuple=False).flatten()\n",
    "        group_indices = [j.item() for j in overlaps if j.item() not in used_indices]\n",
    "\n",
    "        # Debug: Print group information for analysis\n",
    "        print(f\"\\nBox {i}: Initial box {box}, Score: {score}, Class: {cls}\")\n",
    "        print(f\"Group indices (overlapping boxes with IoU > {iou_threshold}): {group_indices}\")\n",
    "        print(f\"IoUs with group indices: {[iou_matrix[i][j].item() for j in group_indices]}\")\n",
    "\n",
    "        if not group_indices:\n",
    "            # No overlapping boxes; add the box as is\n",
    "            final_boxes.append(box)\n",
    "            final_scores.append(score)\n",
    "            final_classes.append(cls)\n",
    "            used_indices.add(i)\n",
    "        else:\n",
    "            # Aggregate overlapping boxes\n",
    "            overlapping_boxes = [all_boxes[j] * all_scores[j] for j in group_indices]\n",
    "            overlapping_scores = [all_scores[j] for j in group_indices]\n",
    "\n",
    "            # Weighted average for the final box\n",
    "            avg_box = np.sum(overlapping_boxes, axis=0) / np.sum(overlapping_scores)\n",
    "\n",
    "            # Average score, optionally scaled by model agreement\n",
    "            avg_score = np.mean(overlapping_scores) * (len(group_indices) / len(model_outputs))\n",
    "\n",
    "            # Append aggregated results\n",
    "            final_boxes.append(avg_box)\n",
    "            final_scores.append(avg_score)\n",
    "            # Select the class of the first box in the group for simplicity\n",
    "            final_classes.append(cls)\n",
    "            used_indices.update(group_indices)  # Mark all grouped indices as used\n",
    "\n",
    "    return np.array(final_boxes), np.array(final_scores), np.array(final_classes)\n",
    "\n",
    "# Example model outputs for testing\n",
    "model_outputs = [\n",
    "    (boxes_yolo, scores_yolo, classes_yolo),\n",
    "    (boxes_detr, scores_detr, classes_detr),\n",
    "    # (boxes_detectron, scores_detectron, classes_detectron)\n",
    "]\n",
    "\n",
    "aggregated_boxes, aggregated_scores, aggregated_classes = aggregate_boxes(model_outputs)\n",
    "\n",
    "print(\"Aggregated boxes:\", aggregated_boxes)\n",
    "print(\"Aggregated scores:\", aggregated_scores)\n",
    "print(\"Aggregated classes:\", aggregated_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading image...\n",
      "Image loaded successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing bounding boxes: 100%|██████████| 2/2 [00:00<00:00, 1988.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drawing box 1 / 2 with score: 0.8529750108718872\n",
      "Adding label: 8: 0.85 at position (146, 122)\n",
      "Drawing box 2 / 2 with score: 0.8674219846725464\n",
      "Adding label: Class0: 0.87 at position (216, 59)\n",
      "Image saved to aggregated_output.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from tqdm import tqdm\n",
    "\n",
    "def draw_aggregated_boxes(image_path, boxes, scores, classes, class_names=None, confidence_threshold=0.5):\n",
    "    \"\"\"\n",
    "    Draws aggregated bounding boxes, scores, and class labels on the image.\n",
    "\n",
    "    Arguments:\n",
    "        image_path (str): Path to the input image.\n",
    "        boxes (ndarray): Array of shape (num_boxes, 4) with bounding box coordinates [x_min, y_min, x_max, y_max].\n",
    "        scores (ndarray): Array of shape (num_boxes,) with confidence scores.\n",
    "        classes (ndarray): Array of shape (num_boxes,) with class labels.\n",
    "        class_names (dict, optional): Dictionary mapping class indices to class names. Defaults to None.\n",
    "        confidence_threshold (float): Minimum confidence score to display a box.\n",
    "    \"\"\"\n",
    "    # Load the image\n",
    "    print(\"Loading image...\")\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        raise ValueError(f\"Image not found at {image_path}\")\n",
    "    print(\"Image loaded successfully.\")\n",
    "\n",
    "    # Process each box and draw if above confidence threshold\n",
    "    for i, box in tqdm(enumerate(boxes), total=len(boxes), desc=\"Processing bounding boxes\"):\n",
    "        score = scores[i]\n",
    "        \n",
    "        # Skip boxes below the confidence threshold\n",
    "        if score < confidence_threshold:\n",
    "            continue\n",
    "\n",
    "        print(f\"Drawing box {i + 1} / {len(boxes)} with score: {score}\")\n",
    "        x_min, y_min, x_max, y_max = map(int, box)\n",
    "        cls = classes[i]\n",
    "        \n",
    "        # Set box color based on class\n",
    "        color = (0, 255, 0)  # Green for bounding box\n",
    "        \n",
    "        # Draw bounding box\n",
    "        cv2.rectangle(image, (x_min, y_min), (x_max, y_max), color, 2)\n",
    "\n",
    "        # Display label with class and confidence\n",
    "        label = f\"{class_names.get(cls, cls)}: {score:.2f}\"\n",
    "        label_size, _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)\n",
    "        label_y = max(y_min, label_size[1] + 10)\n",
    "        \n",
    "        print(f\"Adding label: {label} at position ({x_min}, {label_y - 7})\")\n",
    "        \n",
    "        # Draw the label background and text\n",
    "        cv2.rectangle(image, (x_min, y_min - label_size[1] - 10), (x_min + label_size[0], y_min), color, -1)\n",
    "        cv2.putText(image, label, (x_min, label_y - 7), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "    \n",
    "    # Replace the display part with saving\n",
    "    output_path = \"aggregated_output.jpg\"\n",
    "    cv2.imwrite(output_path, image)\n",
    "    print(f\"Image saved to {output_path}\")\n",
    "\n",
    "\n",
    "# Example usage with class names and confidence threshold\n",
    "class_names = {0: \"Class0\", 55: \"Class55\", 61: \"Class61\"}  # Example class names\n",
    "draw_aggregated_boxes(test_image, aggregated_boxes, aggregated_scores, aggregated_classes, class_names, confidence_threshold=0.0)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
