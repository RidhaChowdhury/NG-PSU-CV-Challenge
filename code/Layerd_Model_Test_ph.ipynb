{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q ultralytics"
      ],
      "metadata": {
        "id": "LpZo0lhdZWt-"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "3KuP7cHxWCkl"
      },
      "outputs": [],
      "source": [
        "#import pytorch and the libraries depending on pytorch\n",
        "import torch\n",
        "import torchvision.models as models\n",
        "#import tensorflow and tf libraries\n",
        "import tensorflow as tf\n",
        "#additional libraries for image processing\n",
        "import numpy as np\n",
        "#import multithreaded executor\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "#import cv2 for image processing\n",
        "import cv2\n",
        "# import matplot to graph\n",
        "import matplotlib.pyplot as plt\n",
        "# OS for general purpose\n",
        "import os\n",
        "\n",
        "#import models\n",
        "from ultralytics import YOLO"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#load all models first\n",
        "\n",
        "#yolo8 for now\n",
        "def load_yolov8():\n",
        "    model = YOLO('yolov8n-cls.pt')\n",
        "    return model\n",
        "\n",
        "#EfficientNet with keras\n",
        "def load_efficientnet():\n",
        "    model = tf.keras.applications.EfficientNetB0(weights='imagenet')\n",
        "    return model\n",
        "\n",
        "#Resnet with tf\n",
        "def load_resnet50():\n",
        "    model = models.resnet50(pretrained=True)\n",
        "    model.eval()\n",
        "    return model"
      ],
      "metadata": {
        "id": "jepe3iIhYtM4"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# preprocess the images for each model\n",
        "def preprocess_image(img, model_name):\n",
        "    if model_name == 'yolo8':\n",
        "        # resize image first\n",
        "        img_resized = cv2.resize(img, (224, 224))\n",
        "        # distribute 0 -> 1 after normalization\n",
        "        img_normalized = img_resized / 255.0\n",
        "        # add the additional dimension so batches can be created\n",
        "        img_yolo = np.expand_dims(img_resized, axis=0).astype('uint8')\n",
        "        return img_yolo\n",
        "    elif model_name == 'efficientnet':\n",
        "        # resize the image again for effnet\n",
        "        img_resized = cv2.resize(img, (224, 224))\n",
        "        # run effnets preprocessing\n",
        "        img_efficientnet = tf.keras.applications.efficientnet.preprocess_input(img_resized)\n",
        "        # add the additional dimension so batches can be created\n",
        "        img_efficientnet = np.expand_dims(img_efficientnet, axis=0)\n",
        "        return img_efficientnet\n",
        "    elif model_name == 'resnet50':\n",
        "        # resize the image again for resnet\n",
        "        img_resized = cv2.resize(img, (224, 224))\n",
        "        # run keras preprocessing\n",
        "        img_resnet = tf.keras.applications.resnet50.preprocess_input(img_resized)\n",
        "        # add the additional dimension so batches can be created\n",
        "        img_resnet = np.expand_dims(img_resnet, axis=0)\n",
        "        return img_resnet\n",
        "    else:\n",
        "        # return 0 on invalid input\n",
        "        return 0"
      ],
      "metadata": {
        "id": "G5umXyHkeiJH"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# classify based on model\n",
        "def classify_image(model, img, model_name):\n",
        "    if model_name == 'yolo8':\n",
        "        # Ensure img is a NumPy array with dtype uint8 and correct shape for YOLOv8\n",
        "        if not isinstance(img, np.ndarray) or img.dtype != np.uint8:\n",
        "            img = np.array(img, dtype=np.uint8)\n",
        "        if len(img.shape) == 4:  # Check if batch dimension is already present\n",
        "            input_img = img\n",
        "        else:  # Add batch dimension if missing\n",
        "            input_img = np.expand_dims(img, axis=0)\n",
        "        results = model(input_img)\n",
        "        probs = np.array(results[0].probs.data)\n",
        "        return probs\n",
        "    elif model_name == 'efficientnet':\n",
        "        # results should already be formatted\n",
        "        predictions = model.predict(img)\n",
        "        return predictions[0]\n",
        "    elif model_name == 'resnet50':\n",
        "        with torch.no_grad():\n",
        "            # copy the images arra\n",
        "            img_copy = img.copy()\n",
        "            # convert image to PyTorch tensor\n",
        "            img_tensor = torch.from_numpy(img_copy).permute(0, 3, 1, 2).float()\n",
        "            img_tensor = img_tensor.to('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "            model = model.to(img_tensor.device)\n",
        "            predictions = model(img_tensor)\n",
        "        return predictions.cpu().numpy().flatten()"
      ],
      "metadata": {
        "id": "VI0SakMki2W0"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# run the models now\n",
        "def classify_with_models(dataset):\n",
        "    # load each model first\n",
        "    yolov8 = load_yolov8()\n",
        "    efficientnet = load_efficientnet()\n",
        "    resnet50 = load_resnet50()\n",
        "\n",
        "    # results array\n",
        "    results = []\n",
        "\n",
        "    # run for each image in the dataset\n",
        "    for img in dataset:\n",
        "        # call the preprocessing function for each model\n",
        "        img_yolo = preprocess_image(img, 'yolo8')\n",
        "        img_efficientnet = preprocess_image(img, 'efficientnet')\n",
        "        img_resnet50 = preprocess_image(img, 'resnet50')\n",
        "\n",
        "        # creat a threadpool to run these simult\n",
        "        with ThreadPoolExecutor() as executor:\n",
        "            yolo_pred = executor.submit(classify_image, yolov8, img_yolo, 'yolo8')\n",
        "            effnet_pred = executor.submit(classify_image, efficientnet, img_efficientnet, 'efficientnet')\n",
        "            future_resnet_pred = executor.submit(classify_image, resnet50, img_resnet50, 'resnet50')\n",
        "\n",
        "            # Get results from each model\n",
        "            yolo_result = yolo_pred.result()\n",
        "            effnet_result = effnet_pred.result()\n",
        "            resnet_result = future_resnet_pred.result()\n",
        "\n",
        "        # average the results\n",
        "        avg_result = (yolo_result + effnet_result + resnet_result) / 3\n",
        "\n",
        "        # store the best result for each image along with the confidence\n",
        "        best_class = np.argmax(avg_result)\n",
        "        confidence = avg_result[best_class]\n",
        "\n",
        "        # add to results array\n",
        "        results.append((best_class, confidence))\n",
        "\n",
        "    return results"
      ],
      "metadata": {
        "id": "CbUQsXcBkteM"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import the images and add them to an array\n",
        "\n",
        "# array set\n",
        "image_dataset = []\n",
        "\n",
        "for filename in os.listdir('test_images'):\n",
        "    img_path = os.path.join('test_images', filename)\n",
        "    img = cv2.imread(img_path)\n",
        "    if img is not None:\n",
        "        # resize the image here and remove redundancy in preprocessing\n",
        "        img_resized = cv2.resize(img, (224, 224))\n",
        "        image_dataset.append(img_resized)\n",
        "\n",
        "# verify if the images have been loaded\n",
        "print(\"Number of images loaded in: \", len(image_dataset))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "czUzKiLkmSk_",
        "outputId": "23305356-9e5d-4b90-fc05-60202de11c30"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of images loaded in:  10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# store in results arrray\n",
        "results = classify_with_models(image_dataset)\n",
        "\n",
        "for i, (best_class, confidence) in enumerate(results):\n",
        "    print(f\"Image {i + 1} - Best Classified Class: {best_class} with confidence: {confidence}\")"
      ],
      "metadata": {
        "id": "fs-J3viLpEEa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "815017c8-9861-4872-ede1-63d90e5bc38d"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 224x224 digital_clock 0.03, nematode 0.03, jellyfish 0.02, theater_curtain 0.02, fire_screen 0.02, 59.2ms\n",
            "Speed: 145.4ms preprocess, 59.2ms inference, 0.1ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
            "\n",
            "0: 224x224 digital_clock 0.03, nematode 0.03, jellyfish 0.02, theater_curtain 0.02, fire_screen 0.02, 25.0ms\n",
            "Speed: 151.3ms preprocess, 25.0ms inference, 0.1ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step\n",
            "\n",
            "0: 224x224 digital_clock 0.03, nematode 0.03, jellyfish 0.02, theater_curtain 0.02, fire_screen 0.02, 41.6ms\n",
            "Speed: 163.3ms preprocess, 41.6ms inference, 0.2ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step\n",
            "\n",
            "0: 224x224 digital_clock 0.03, nematode 0.03, jellyfish 0.02, theater_curtain 0.02, fire_screen 0.02, 45.9ms\n",
            "Speed: 243.7ms preprocess, 45.9ms inference, 0.1ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step\n",
            "\n",
            "0: 224x224 digital_clock 0.03, nematode 0.03, jellyfish 0.02, theater_curtain 0.02, fire_screen 0.02, 39.0ms\n",
            "Speed: 178.7ms preprocess, 39.0ms inference, 0.1ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step\n",
            "\n",
            "0: 224x224 digital_clock 0.03, nematode 0.03, jellyfish 0.02, theater_curtain 0.02, fire_screen 0.02, 65.7ms\n",
            "Speed: 247.4ms preprocess, 65.7ms inference, 0.1ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step\n",
            "\n",
            "0: 224x224 digital_clock 0.03, nematode 0.03, jellyfish 0.02, theater_curtain 0.02, fire_screen 0.02, 32.3ms\n",
            "Speed: 137.6ms preprocess, 32.3ms inference, 0.1ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step\n",
            "\n",
            "0: 224x224 digital_clock 0.03, nematode 0.03, jellyfish 0.02, theater_curtain 0.02, fire_screen 0.02, 66.4ms\n",
            "Speed: 157.5ms preprocess, 66.4ms inference, 0.1ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step\n",
            "\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 276ms/step\n",
            "0: 224x224 digital_clock 0.03, nematode 0.03, jellyfish 0.02, theater_curtain 0.02, fire_screen 0.02, 104.1ms\n",
            "Speed: 406.0ms preprocess, 104.1ms inference, 0.1ms postprocess per image at shape (1, 3, 224, 224)\n",
            "\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step\n",
            "0: 224x224 digital_clock 0.03, nematode 0.03, jellyfish 0.02, theater_curtain 0.02, fire_screen 0.02, 100.1ms\n",
            "Speed: 382.2ms preprocess, 100.1ms inference, 0.1ms postprocess per image at shape (1, 3, 224, 224)\n",
            "Image 1 - Best Classified Class: 818 with confidence: 182.80162048339844\n",
            "Image 2 - Best Classified Class: 818 with confidence: 190.0572967529297\n",
            "Image 3 - Best Classified Class: 818 with confidence: 157.4588165283203\n",
            "Image 4 - Best Classified Class: 818 with confidence: 158.20233154296875\n",
            "Image 5 - Best Classified Class: 818 with confidence: 230.0871124267578\n",
            "Image 6 - Best Classified Class: 818 with confidence: 213.335693359375\n",
            "Image 7 - Best Classified Class: 818 with confidence: 153.1457977294922\n",
            "Image 8 - Best Classified Class: 818 with confidence: 191.89923095703125\n",
            "Image 9 - Best Classified Class: 818 with confidence: 151.91343688964844\n",
            "Image 10 - Best Classified Class: 818 with confidence: 197.38739013671875\n"
          ]
        }
      ]
    }
  ]
}